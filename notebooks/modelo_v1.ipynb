{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Augusto e Ícaro\n",
    "## Modelo de automatização das Heurísticas de Nielsen para comentários em reviews de Apps\n",
    "\n",
    "* Versão 1.0\n",
    "* Bibliotecas utilizadas: pandas, numpy, texthero, ntlk e corpus do ntlk em português\n",
    "* Dataset utilizado: dataset_v4.csv\n",
    "* Data: 22/07/2020\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "[x] Pre processamento detalhado\n",
    "\n",
    "[x] Pipeline de pre-processamento\n",
    "\n",
    "[x] Classificador baseado em ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: texthero in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.9)\n",
      "Requirement already satisfied: nltk>=3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.5)\n",
      "Requirement already satisfied: tqdm>=4.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.46.1)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: gensim>=3.6.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.8.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (0.23.1)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (2.3.2)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.1.1)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (0.15.1)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (2.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.7.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (47.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: pillow in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: boto in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.14.23)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.4.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.6.1)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.23 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.17.23)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.23->boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.15.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.5)\r\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (2020.6.8)\r\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (0.15.1)\r\n",
      "Requirement already satisfied: tqdm in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (4.46.1)\r\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (7.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install texthero \n",
    "!{sys.executable} -m pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import nltk\n",
    "import numpy as np\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa versão iremos testar apenas com textos em ingles, sem adicionar os pesos de sentimentos e heurísticas de Nielsen. Queremos treinar o modelo para classificar apenas em usabilidade ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negócio de reconhecimento facialnão funciona. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um lixo!!! 9 tentativas de econhecimento facia...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horrível! Pior que FBI! Se fosse pra receberem...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meio difícil fazer sem óculos mais deu certo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não serve pra nada , não dá para acessar,péssimo.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  Negócio de reconhecimento facialnão funciona. ...          True   \n",
       "1  Um lixo!!! 9 tentativas de econhecimento facia...         False   \n",
       "2  Horrível! Pior que FBI! Se fosse pra receberem...          True   \n",
       "3       Meio difícil fazer sem óculos mais deu certo          True   \n",
       "4  Não serve pra nada , não dá para acessar,péssimo.          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'is_usability', 'is_classified']\n",
    "df = pd.read_csv(\"reviews_v4.csv\", index_col=False, usecols=cols)\n",
    "df = df.rename(columns={'Text': 'text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    755\n",
       "True     175\n",
       "Name: is_usability, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    548\n",
       "True     381\n",
       "Name: is_classified, dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_classified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dados\n",
    "\n",
    "O pipeline padrão remove dígitos, pontuação, remove diacritics, stopwords em inglês e whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function texthero.preprocessing.fillna(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.lowercase(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_digits(input: pandas.core.series.Series, only_blocks=True) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_punctuation(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_diacritics(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_stopwords(input: pandas.core.series.Series, stopwords: Union[Set[str], NoneType] = None, remove_str_numbers=False) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_whitespace(input: pandas.core.series.Series) -> pandas.core.series.Series>]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = hero.preprocessing.get_default_pipeline()\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negocio de reconhecimento facialnao funciona n...\n",
       "1      um lixo tentativas de econhecimento facial sem...\n",
       "2      horrivel pior que fbi se fosse pra receberem a...\n",
       "3           meio dificil fazer sem oculos mais deu certo\n",
       "4         nao serve pra nada nao da para acessar pessimo\n",
       "                             ...                        \n",
       "925    como eu faco pra entrar na minha conta enem pe...\n",
       "926    sim facilita muito em varios servicos e mais i...\n",
       "927    nao consigo acessar meu auxilio como faco pra ...\n",
       "928                                  seguro hiper seguro\n",
       "929    otimo porem e bom implementar novas funcionali...\n",
       "Name: text, Length: 930, dtype: object"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_functions_indexes = [0, 1, 2, 5, 6]\n",
    "pipeline = [pipeline[i] for i in selected_functions_indexes]\n",
    "df['text'] = hero.preprocessing.clean(df['text'])\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Removendo stopwords em português com o corpus em portugês do NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negocio  reconhecimento facialnao funciona nao  pra ficar dia todo nisso nao arrumem   favor'"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('portuguese')\n",
    "df['text'] = hero.remove_stopwords(df['text'], stopwords=stopwords)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negoci reconhec facialna funcion nao pra fic dia tod niss nao arrum favor'"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.stem(df['text'], language='portuguese')\n",
    "df['text']\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[negoci, reconhec, facialna, funcion, nao, pra...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lix, tentat, econhec, facial, exit, dur, depe...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horrivel, pior, fbi, pra, receb, algo, gent, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mei, dificil, faz, ocul, deu, cert]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nao, serv, pra, nad, nao, acess, pessim]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  [negoci, reconhec, facialna, funcion, nao, pra...          True   \n",
       "1  [lix, tentat, econhec, facial, exit, dur, depe...         False   \n",
       "2  [horrivel, pior, fbi, pra, receb, algo, gent, ...          True   \n",
       "3               [mei, dificil, faz, ocul, deu, cert]          True   \n",
       "4          [nao, serv, pra, nad, nao, acess, pessim]          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.tokenize(df['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_name'] = df.apply(lambda row: 'usability' if row['is_usability'] else 'not_usability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['negoci',\n",
       "  'reconhec',\n",
       "  'facialna',\n",
       "  'funcion',\n",
       "  'nao',\n",
       "  'pra',\n",
       "  'fic',\n",
       "  'dia',\n",
       "  'tod',\n",
       "  'niss',\n",
       "  'nao',\n",
       "  'arrum',\n",
       "  'favor'],\n",
       " 'is_classified': True,\n",
       " 'class_name': 'usability'}"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('is_usability', 1)\n",
    "df = df.to_dict('records')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "Nessa parte, iremos treinar e utilizar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para aprendizado dos dados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(training_data):\n",
    "    corpus_words = {}\n",
    "    for data in training_data: \n",
    "        class_name = data['class_name']\n",
    "        frase = data['text']\n",
    "        if class_name not in list(corpus_words.keys()):\n",
    "            corpus_words[class_name] = {}\n",
    "        for word in frase:\n",
    "            if word not in list(corpus_words[class_name].keys()):\n",
    "                corpus_words[class_name][word] = 1\n",
    "            else:\n",
    "                corpus_words[class_name][word] += 1\n",
    "    return corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(corpus, sentence):\n",
    "    def calculate_class_score(corpus_words, sentence, class_name):\n",
    "        score = 0 \n",
    "        for word in sentence:\n",
    "            if word in corpus_words[class_name]:\n",
    "                score += corpus_words[class_name][word]\n",
    "        return score\n",
    "    classifications = []\n",
    "    for class_name in corpus.keys():\n",
    "        classifications.append({'class_name': class_name, 'score': calculate_class_score(corpus, sentence, class_name)})    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para normalizar os scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(classification):\n",
    "    total_score = sum(score['score'] for score in classification['scores'])\n",
    "    for score in classification['scores']:\n",
    "        score['score'] = score['score']/total_score\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo o dataset dos classificados em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test cases 39\n",
      "Total train cases 343\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "classified_df = []\n",
    "unclassified_df = []\n",
    "\n",
    "for data in df:\n",
    "    classified_df.append(data) if data['is_classified'] else unclassified_df.append(data)\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "    \n",
    "for i in classified_df:\n",
    "    r = random.uniform(0,1)\n",
    "    if r <= 0.1:\n",
    "        test_dataset.append(i)\n",
    "    else:\n",
    "        train_dataset.append(i)\n",
    "\n",
    "print(f'Total test cases {len(test_dataset)}')\n",
    "print(f'Total train cases {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtd usability keys 765\n",
      "qtd not_usability keys 568\n"
     ]
    }
   ],
   "source": [
    "corpus = learning(classified_df)\n",
    "print(f'qtd usability keys {len(corpus[\"usability\"].keys())}')\n",
    "print(f'qtd not_usability keys {len(corpus[\"not_usability\"].keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [{'test_data': test_data, 'scores': get_scores(corpus, test_data['text'])} for test_data in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_data': {'text': ['pessim', 'pessim', 'pessim', 'nad', 'nel', 'funcion'],\n",
       "  'is_classified': True,\n",
       "  'class_name': 'not_usability'},\n",
       " 'scores': [{'class_name': 'usability', 'score': 0.45302013422818793},\n",
       "  {'class_name': 'not_usability', 'score': 0.5469798657718121}]}"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = [normalize_scores(classification) for classification in classifications]\n",
    "classifications[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 - Has: usability - 0.45302013422818793 and  not_usability - 0.5469798657718121 and original result is: not_usability\n",
      "Test 1 - Has: usability - 0.6361788617886179 and  not_usability - 0.3638211382113821 and original result is: usability\n",
      "Test 2 - Has: usability - 0.6589147286821705 and  not_usability - 0.34108527131782945 and original result is: usability\n",
      "Test 3 - Has: usability - 0.6176470588235294 and  not_usability - 0.38235294117647056 and original result is: not_usability\n",
      "Test 4 - Has: usability - 0.6339227242960053 and  not_usability - 0.3660772757039948 and original result is: not_usability\n",
      "Test 5 - Has: usability - 0.5555555555555556 and  not_usability - 0.4444444444444444 and original result is: not_usability\n",
      "Test 6 - Has: usability - 0.7076648841354723 and  not_usability - 0.29233511586452765 and original result is: usability\n",
      "Test 7 - Has: usability - 0.0 and  not_usability - 1.0 and original result is: not_usability\n",
      "Test 8 - Has: usability - 0.6878612716763006 and  not_usability - 0.31213872832369943 and original result is: usability\n",
      "Test 9 - Has: usability - 0.7017543859649122 and  not_usability - 0.2982456140350877 and original result is: usability\n",
      "Test 10 - Has: usability - 0.6246215943491423 and  not_usability - 0.3753784056508577 and original result is: not_usability\n",
      "Test 11 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 12 - Has: usability - 0.6295884315906563 and  not_usability - 0.3704115684093437 and original result is: not_usability\n",
      "Test 13 - Has: usability - 0.6836734693877551 and  not_usability - 0.3163265306122449 and original result is: usability\n",
      "Test 14 - Has: usability - 0.6190476190476191 and  not_usability - 0.38095238095238093 and original result is: not_usability\n",
      "Test 15 - Has: usability - 0.3333333333333333 and  not_usability - 0.6666666666666666 and original result is: not_usability\n",
      "Test 16 - Has: usability - 0.6363636363636364 and  not_usability - 0.36363636363636365 and original result is: usability\n",
      "Test 17 - Has: usability - 0.16666666666666666 and  not_usability - 0.8333333333333334 and original result is: not_usability\n",
      "Test 18 - Has: usability - 0.639618138424821 and  not_usability - 0.360381861575179 and original result is: not_usability\n",
      "Test 19 - Has: usability - 0.6363636363636364 and  not_usability - 0.36363636363636365 and original result is: not_usability\n",
      "Test 20 - Has: usability - 0.125 and  not_usability - 0.875 and original result is: not_usability\n",
      "Test 21 - Has: usability - 0.6554850407978241 and  not_usability - 0.3445149592021759 and original result is: not_usability\n",
      "Test 22 - Has: usability - 0.6473087818696884 and  not_usability - 0.3526912181303116 and original result is: not_usability\n",
      "Test 23 - Has: usability - 0.6491372226787182 and  not_usability - 0.35086277732128185 and original result is: not_usability\n",
      "Test 24 - Has: usability - 0.6649874055415617 and  not_usability - 0.3350125944584383 and original result is: usability\n",
      "Test 25 - Has: usability - 0.5896551724137931 and  not_usability - 0.4103448275862069 and original result is: not_usability\n",
      "Test 26 - Has: usability - 0.671863926293409 and  not_usability - 0.3281360737065911 and original result is: usability\n",
      "Test 27 - Has: usability - 0.5934959349593496 and  not_usability - 0.4065040650406504 and original result is: not_usability\n",
      "Test 28 - Has: usability - 0.6417525773195877 and  not_usability - 0.3582474226804124 and original result is: not_usability\n",
      "Test 29 - Has: usability - 0.6611353711790393 and  not_usability - 0.3388646288209607 and original result is: usability\n",
      "Test 30 - Has: usability - 0.5155555555555555 and  not_usability - 0.48444444444444446 and original result is: not_usability\n",
      "Test 31 - Has: usability - 0.692429022082019 and  not_usability - 0.30757097791798105 and original result is: usability\n",
      "Test 32 - Has: usability - 0.5 and  not_usability - 0.5 and original result is: not_usability\n",
      "Test 33 - Has: usability - 0.6183783783783784 and  not_usability - 0.3816216216216216 and original result is: not_usability\n",
      "Test 34 - Has: usability - 0.0 and  not_usability - 1.0 and original result is: not_usability\n",
      "Test 35 - Has: usability - 0.6923076923076923 and  not_usability - 0.3076923076923077 and original result is: not_usability\n",
      "Test 36 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 37 - Has: usability - 0.6818181818181818 and  not_usability - 0.3181818181818182 and original result is: usability\n",
      "Test 38 - Has: usability - 0.7011834319526628 and  not_usability - 0.2988165680473373 and original result is: usability\n"
     ]
    }
   ],
   "source": [
    "for i, classification in enumerate(classifications):\n",
    "    message = \"\"\n",
    "    message = message + f'Test {i} - Has:'\n",
    "    for score in classification['scores']:\n",
    "        message = message + \" \" + score['class_name'] + \" - \" + str(score['score'])  + \" and \"\n",
    "    message = message + \"original result is: \" + classification['test_data']['class_name']\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy is: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "right_answers = 0\n",
    "for i, classification in enumerate(classifications):\n",
    "    higher_score = max(classification['scores'], key=lambda x:x['score'])\n",
    "    if classification['test_data']['class_name'] == higher_score['class_name']:\n",
    "        right_answers += 1\n",
    "\n",
    "print(f'Final accuracy is: {right_answers/len(classifications)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
