{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Augusto e Ícaro\n",
    "## Modelo de automatização das Heurísticas de Nielsen para comentários em reviews de Apps\n",
    "\n",
    "* Versão 0.3.0\n",
    "* Bibliotecas utilizadas: pandas, numpy, texthero, ntlk e corpus do ntlk em português\n",
    "* Dataset utilizado: dataset_v9.csv\n",
    "* Data: 04/07/2020\n",
    "\n",
    "### Objetivos, incrementos e correções:\n",
    "\n",
    "* Encapsulamento da pipeline de pre-processamento\n",
    "* Utilizando dataset com classificação revisada para melhor acurácia\n",
    "* Aumento dos pesos de termos classificados como usabilidade\n",
    "* Foco em detalhar e evoluir o dicionário de radicais classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.2.1-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2\n",
      "    Uninstalling pip-20.2:\n",
      "      Successfully uninstalled pip-20.2\n",
      "Successfully installed pip-20.2.1\n",
      "Requirement already satisfied: pandas in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: texthero in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.9)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (0.23.1)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.7.0)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (2.3.2)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.1.1)\n",
      "Requirement already satisfied: tqdm>=4.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.46.1)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: gensim>=3.6.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.8.3)\n",
      "Requirement already satisfied: nltk>=3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.5)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: six in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (2.1.0)\n",
      "Requirement already satisfied: pillow in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (47.3.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.7.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (7.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (2020.6.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.25.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.6.1)\n",
      "Requirement already satisfied: boto3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.14.23)\n",
      "Requirement already satisfied: boto in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.23 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.17.23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.23->boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.15.2)\n",
      "Requirement already satisfied: nltk in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (0.15.1)\n",
      "Requirement already satisfied: tqdm in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (4.46.1)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install texthero \n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPLIST_FILENAME='droplist.0.2.0.txt'\n",
    "MODEL_FILENAME='model_v0.2.0.json'\n",
    "DATASET_FILENAME='reviews_v9.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df_path, df_cols):\n",
    "    df = pd.read_csv(df_path, index_col=False, usecols=df_cols)\n",
    "    df = df[df['is_classified']==True]\n",
    "    df = df.rename(columns={'Text': 'text'})\n",
    "    df['text'] = hero.preprocessing.clean(df['text'])\n",
    "    pt_stopwords = stopwords.words('portuguese')\n",
    "    df['text'] = hero.remove_stopwords(df['text'], stopwords=pt_stopwords)\n",
    "    df['text'] = hero.stem(df['text'], language='portuguese')\n",
    "    df['text'] = hero.tokenize(df['text'])\n",
    "    df['class_name'] = df.apply(lambda row: 'usability' if row['is_usability'] else 'not_usability', axis=1)\n",
    "    df = df.drop('is_usability', 1)\n",
    "    df = df.to_dict('records')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, train_size):\n",
    "    \n",
    "    df_usa = [item for item in df if item['class_name'] == 'usability']\n",
    "    df_not_usa = [item for item in df if item not in df_usa]\n",
    "    \n",
    "    train_usa, test_usa = np.split(df_usa, [int(len(df_usa)*train_size)])\n",
    "    train_not_usa, test_not_usa = np.split(df_not_usa, [int(len(df_not_usa)*train_size)])\n",
    "    \n",
    "    return np.concatenate([train_usa,train_not_usa]), np.concatenate([test_usa,test_not_usa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process(DATASET_FILENAME, ['ID', 'Text', 'is_usability', 'is_classified'])\n",
    "train_dataset, test_dataset = split_train_test(df, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 650 test: 280\n"
     ]
    }
   ],
   "source": [
    "print(f'train: {len(train_dataset)} test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] total usability train data 497\n",
      "[info] total not_usability train data 153\n",
      "[info] total usability test data 214\n",
      "[info] total not_usability test data 66\n"
     ]
    }
   ],
   "source": [
    "print(f'[info] total usability train data {sum(value[\"class_name\"] == \"usability\" for value in train_dataset)}')\n",
    "print(f'[info] total not_usability train data {sum(value[\"class_name\"] == \"not_usability\" for value in train_dataset)}')\n",
    "print(f'[info] total usability test data {sum(value[\"class_name\"] == \"usability\" for value in test_dataset)}')\n",
    "print(f'[info] total not_usability test data {sum(value[\"class_name\"] == \"not_usability\" for value in test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data):\n",
    "    corpus_words = {}\n",
    "    for data in training_data: \n",
    "        class_name = data['class_name']\n",
    "        frase = data['text']\n",
    "        if class_name not in list(corpus_words.keys()):\n",
    "            corpus_words[class_name] = {}\n",
    "        for word in frase:\n",
    "            if word not in list(corpus_words[class_name].keys()):\n",
    "                corpus_words[class_name][word] = 1\n",
    "            else:\n",
    "                corpus_words[class_name][word] += 1\n",
    "    return corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_score(corpus_words, min_value, by_key):\n",
    "    fitered_dict = {}\n",
    "    for k in corpus.keys():\n",
    "        if by_key:\n",
    "            if k == by_key:\n",
    "                fitered_dict.update({k: { key:value for (key,value) in corpus[k].items() if value > min_value }})\n",
    "            else:\n",
    "                fitered_dict.update({k: { key:value for (key,value) in corpus[k].items() }})\n",
    "        else:\n",
    "            fitered_dict.update({k: { key:value for (key,value) in corpus[k].items() if value > min_value }})\n",
    "    return fitered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(corpus, sentence):\n",
    "    def calculate_class_score(corpus_words, sentence, class_name):\n",
    "        score = 0 \n",
    "        for word in sentence:\n",
    "            if word in corpus_words[class_name]:\n",
    "                score += corpus_words[class_name][word]\n",
    "        return score\n",
    "    classifications = []\n",
    "    for class_name in corpus.keys():\n",
    "        classifications.append({'class_name': class_name, 'score': calculate_class_score(corpus, sentence, class_name)})    \n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(classification):\n",
    "    total_score = sum(score['score'] for score in classification['scores'])\n",
    "    if total_score != 0:\n",
    "        for score in classification['scores']:\n",
    "            score['score'] = score['score']/total_score\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_score_targets(corpus, targets, boost_val):\n",
    "    boosted_dict = {}\n",
    "    for k in corpus.keys():\n",
    "        if k in targets:\n",
    "            boosted_dict.update({k: { key:value*boost_val for (key,value) in corpus[k].items() }})\n",
    "        else:\n",
    "            boosted_dict.update({k: { key:value for (key,value) in corpus[k].items() }})\n",
    "    return boosted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(classifications):\n",
    "    accuracies = {\n",
    "        'usability': 0,\n",
    "        'not_usability': 0,\n",
    "        'draws': 0\n",
    "    }\n",
    "    class_usa = []\n",
    "    for classification in classifications:\n",
    "        scores = [item['score'] for item in classification['scores']]\n",
    "        is_draw = len(set(scores)) == 1\n",
    "        if is_draw:\n",
    "            accuracies['draws'] +=1\n",
    "            continue\n",
    "        highest_score = max(classification['scores'], key=lambda x:x['score'])\n",
    "        is_draw = False\n",
    "        if classification['test_data']['class_name'] == highest_score['class_name']:\n",
    "            accuracies[highest_score['class_name']] += 1\n",
    "            if(classification['test_data']['class_name']=='usability'):\n",
    "                class_usa.append(classification)\n",
    "        else:\n",
    "            if(classification['test_data']['class_name']=='not_usability'):\n",
    "                print(classification)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unwanted_words(corpus, droplist):\n",
    "    filtered_dict = {}\n",
    "    for k in corpus.keys():\n",
    "        filtered_dict.update({k: { key:value for (key,value) in corpus[k].items() if key not in droplist }})\n",
    "    return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = open(DROPLIST_FILENAME).read().splitlines()\n",
    "corpus = train(train_dataset)\n",
    "# corpus = drop_low_score(corpus, 10, 'usability') # magic number\n",
    "# corpus = drop_low_score(corpus, 10, 'not_usability') # magic number\n",
    "corpus = drop_unwanted_words(corpus, droplist)\n",
    "corpus = boost_score_targets(corpus, ['usability'], 1) # magic number\n",
    "corpus = boost_score_targets(corpus, ['not_usability'], 20) # magic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total words for usability: 810 \n",
      " total words for not_usability: 86 \n"
     ]
    }
   ],
   "source": [
    "for key in corpus.keys():\n",
    "    print(f' total words for {key}: {len(corpus[key].keys())} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [{'test_data': test_data, 'scores': classificate(corpus, test_data['text'])} for test_data in test_dataset]\n",
    "classifications = [normalize_scores(classification) for classification in classifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_data': {'ID': 'gp:AOqpTOGycTCJ9fSb3Flzi-E7KWoPeWpGhoH03kkRc5XNaa7YurpjLwVNyp-OvJPjM_QLkhaVe_nnK0DCaQR46w', 'text': ['funcion'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.7802197802197802}, {'class_name': 'not_usability', 'score': 0.21978021978021978}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGyXTwzF9TQXXZPQOgXid8XoG2-tMi_SkEb2xyJutEd0JquYxnC6YJqxBtOPMo-1AFaQtpJYkb8yE055Q', 'text': ['nao', 'consegu', 'entrar'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.6491228070175439}, {'class_name': 'not_usability', 'score': 0.3508771929824561}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOH86v8Fg39h4yjKdfsm4F3RYg7PWGGpwBg9PUabbYpBR4V-6DkBQ_AS28Z-6UJ2LLkNomZ1kxebV2dcOA', 'text': ['aplic', 'pessim'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFgwwe6S-sYI6whuPRba1iJCjy3oxyQyJuvEpHygPM2je5gAVHky7ysnIU18jiq121xE4OBk_5Xa5QEcw', 'text': ['nao', 'consig', 'acess'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.739413680781759}, {'class_name': 'not_usability', 'score': 0.26058631921824105}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFyJvai8TkvQ3WkYYuOxR7kQk-HEVEMCfYLhIpFUtWfevUNLzn6v4-l8KDz8URi3VM1xHGv1D811S-u1w', 'text': ['nao', 'consig', 'acess'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.739413680781759}, {'class_name': 'not_usability', 'score': 0.26058631921824105}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOE0Uw4lWL8MatIOv5Hh4RG9mlq20uorKH-B_9Id_8xzVlFcEd4KeqD0qKDEbSe057rst4AnxmFW7l4RAw', 'text': ['nao', 'serv', 'nad'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.5604395604395604}, {'class_name': 'not_usability', 'score': 0.43956043956043955}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOHrRkUqllgLPy_gCe5fmre5kkQg9Pvd-Wj6Dwp4P1emagWmDyT1CYVMgMfNwbxf0hFY36n8bHoE-D9HlQ', 'text': ['horrivel', 'atrapalh'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEmhvarDkCoCfNQu-lfNPAwf4Z5TsoSTiYAy7g-5EMe5jZRiy8J5K1RgZONAqQfaBlrkzxAxjVGbN097Q', 'text': ['claudi', 'faustin', 'silv'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGciov-5C-2SBPhFF8l_0HplhU8MfyjFpapS_SWsrjDH_4uts8OfJbgCn_xU02Ywcfy-QQiAlLa8kYaWw', 'text': ['aplic', 'pessim'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGtFeGleSuBGO7J2-LkfApYVTCwreQ6DFYzcHvM2nJrAdKkzqssyd2_9UaoUKLq69MP5cI4bk3J06xTig', 'text': ['complic', 'afff'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEsw_yh3duqNyisljbcST0EAWAy4V9dDjBa0nXUe-M2yFgwdoZO70s8CBJwndG2m1mEjqNC9gcQqLU74g', 'text': ['nao', 'consegu', 'cadastr'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.9065420560747663}, {'class_name': 'not_usability', 'score': 0.09345794392523364}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFt14u5lreBZbC8CGXQB73YgEODKSEujstnfZHMrT_ik6JVi1oZMyl5O8K7JQiiY02D1oUj8VSZqg6Nqg', 'text': ['horrivel', 'aplic'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEqtzZDbJr2ZjY2WGOhiQ0dHrGH8CX7YlgquUazJZJe-DQQyBfUGCEA1T9RBSnxyNfLQyvOC7sZ2Rlckg', 'text': ['vou', 'test', 'dou'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.5121951219512195}, {'class_name': 'not_usability', 'score': 0.4878048780487805}]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-648-a2d704525ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_usa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifications\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-646-472e51a7631d>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(classifications)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhighest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'usability'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mclass_usa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'not_usability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "accuracy, cls_usa = get_accuracy(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right answers Usability: 205 of 214 (0.9579439252336449)\n",
      "Right answers Not Usability: 29 of 66 (0.4393939393939394)\n",
      "Draws: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Right answers Usability: {accuracy[\"usability\"]} of {len([data for data in test_dataset if data[\"class_name\"]==\"usability\"])} ({accuracy[\"usability\"]/len([data for data in test_dataset if data[\"class_name\"]==\"usability\"])})')\n",
    "print(f'Right answers Not Usability: {accuracy[\"not_usability\"]} of {len([data for data in test_dataset if data[\"class_name\"]==\"not_usability\"])} ({accuracy[\"not_usability\"]/len([data for data in test_dataset if data[\"class_name\"]==\"not_usability\"])})')\n",
    "print(f'Draws: {accuracy[\"draws\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_data': {'ID': 'gp:AOqpTOGycTCJ9fSb3Flzi-E7KWoPeWpGhoH03kkRc5XNaa7YurpjLwVNyp-OvJPjM_QLkhaVe_nnK0DCaQR46w', 'text': ['funcion'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.7802197802197802}, {'class_name': 'not_usability', 'score': 0.21978021978021978}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGyXTwzF9TQXXZPQOgXid8XoG2-tMi_SkEb2xyJutEd0JquYxnC6YJqxBtOPMo-1AFaQtpJYkb8yE055Q', 'text': ['nao', 'consegu', 'entrar'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.6491228070175439}, {'class_name': 'not_usability', 'score': 0.3508771929824561}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOH86v8Fg39h4yjKdfsm4F3RYg7PWGGpwBg9PUabbYpBR4V-6DkBQ_AS28Z-6UJ2LLkNomZ1kxebV2dcOA', 'text': ['aplic', 'pessim'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFgwwe6S-sYI6whuPRba1iJCjy3oxyQyJuvEpHygPM2je5gAVHky7ysnIU18jiq121xE4OBk_5Xa5QEcw', 'text': ['nao', 'consig', 'acess'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.739413680781759}, {'class_name': 'not_usability', 'score': 0.26058631921824105}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFyJvai8TkvQ3WkYYuOxR7kQk-HEVEMCfYLhIpFUtWfevUNLzn6v4-l8KDz8URi3VM1xHGv1D811S-u1w', 'text': ['nao', 'consig', 'acess'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.739413680781759}, {'class_name': 'not_usability', 'score': 0.26058631921824105}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOE0Uw4lWL8MatIOv5Hh4RG9mlq20uorKH-B_9Id_8xzVlFcEd4KeqD0qKDEbSe057rst4AnxmFW7l4RAw', 'text': ['nao', 'serv', 'nad'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.5604395604395604}, {'class_name': 'not_usability', 'score': 0.43956043956043955}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOHrRkUqllgLPy_gCe5fmre5kkQg9Pvd-Wj6Dwp4P1emagWmDyT1CYVMgMfNwbxf0hFY36n8bHoE-D9HlQ', 'text': ['horrivel', 'atrapalh'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEmhvarDkCoCfNQu-lfNPAwf4Z5TsoSTiYAy7g-5EMe5jZRiy8J5K1RgZONAqQfaBlrkzxAxjVGbN097Q', 'text': ['claudi', 'faustin', 'silv'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGciov-5C-2SBPhFF8l_0HplhU8MfyjFpapS_SWsrjDH_4uts8OfJbgCn_xU02Ywcfy-QQiAlLa8kYaWw', 'text': ['aplic', 'pessim'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOGtFeGleSuBGO7J2-LkfApYVTCwreQ6DFYzcHvM2nJrAdKkzqssyd2_9UaoUKLq69MP5cI4bk3J06xTig', 'text': ['complic', 'afff'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 1.0}, {'class_name': 'not_usability', 'score': 0.0}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEsw_yh3duqNyisljbcST0EAWAy4V9dDjBa0nXUe-M2yFgwdoZO70s8CBJwndG2m1mEjqNC9gcQqLU74g', 'text': ['nao', 'consegu', 'cadastr'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.9065420560747663}, {'class_name': 'not_usability', 'score': 0.09345794392523364}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOFt14u5lreBZbC8CGXQB73YgEODKSEujstnfZHMrT_ik6JVi1oZMyl5O8K7JQiiY02D1oUj8VSZqg6Nqg', 'text': ['horrivel', 'aplic'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.782608695652174}, {'class_name': 'not_usability', 'score': 0.21739130434782608}]}\n",
      "{'test_data': {'ID': 'gp:AOqpTOEqtzZDbJr2ZjY2WGOhiQ0dHrGH8CX7YlgquUazJZJe-DQQyBfUGCEA1T9RBSnxyNfLQyvOC7sZ2Rlckg', 'text': ['vou', 'test', 'dou'], 'is_classified': True, 'class_name': 'not_usability'}, 'scores': [{'class_name': 'usability', 'score': 0.5121951219512195}, {'class_name': 'not_usability', 'score': 0.4878048780487805}]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-647-32c94a811e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassificate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifications\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-646-472e51a7631d>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(classifications)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhighest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'usability'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mclass_usa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'not_usability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# is this correct?\n",
    "classifications = [{'test_data': test_data, 'scores': classificate(corpus, test_data['text'])} for test_data in df]\n",
    "classifications = [normalize_scores(classification) for classification in classifications]\n",
    "accuracy = get_accuracy(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right answers Usability: 693 of 711 (0.9746835443037974)\n",
      "Right answers Not Usability: 140 of 219 (0.639269406392694)\n",
      "Draws: 36\n"
     ]
    }
   ],
   "source": [
    "print(f'Right answers Usability: {accuracy[\"usability\"]} of {len([data for data in df if data[\"class_name\"]==\"usability\"])} ({accuracy[\"usability\"]/len([data for data in df if data[\"class_name\"]==\"usability\"])})')\n",
    "print(f'Right answers Not Usability: {accuracy[\"not_usability\"]} of {len([data for data in df if data[\"class_name\"]==\"not_usability\"])} ({accuracy[\"not_usability\"]/len([data for data in df if data[\"class_name\"]==\"not_usability\"])})')\n",
    "print(f'Draws: {accuracy[\"draws\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usability': {'consig': 137,\n",
       "  'rost': 20,\n",
       "  'acess': 90,\n",
       "  'erro': 44,\n",
       "  'cadastr': 156,\n",
       "  'fot': 30,\n",
       "  'porqu': 13,\n",
       "  'ruim': 24,\n",
       "  'dad': 32,\n",
       "  'sempr': 12,\n",
       "  'coloc': 17,\n",
       "  'cnh': 28,\n",
       "  'numer': 17,\n",
       "  'cpf': 39,\n",
       "  'ped': 27,\n",
       "  'sei': 11,\n",
       "  'fac': 47,\n",
       "  'pod': 23,\n",
       "  'ter': 26,\n",
       "  'opca': 26,\n",
       "  'faz': 101,\n",
       "  'tod': 24,\n",
       "  'fiz': 37,\n",
       "  'q': 25,\n",
       "  'mail': 17,\n",
       "  'cont': 57,\n",
       "  'aind': 11,\n",
       "  'tent': 55,\n",
       "  'mud': 13,\n",
       "  'fal': 21,\n",
       "  'recuper': 67,\n",
       "  'senh': 176,\n",
       "  'entrar': 36,\n",
       "  'outr': 22,\n",
       "  'form': 11,\n",
       "  'reconhec': 63,\n",
       "  'facial': 66,\n",
       "  'dev': 13,\n",
       "  'app': 74,\n",
       "  'validaca': 19,\n",
       "  'lix': 17,\n",
       "  'temp': 21,\n",
       "  'biometr': 28,\n",
       "  'consegu': 38,\n",
       "  'aplic': 72,\n",
       "  'celul': 14,\n",
       "  'prov': 21,\n",
       "  'vid': 27,\n",
       "  'diz': 54,\n",
       "  'tir': 17,\n",
       "  'dess': 13,\n",
       "  'ser': 19,\n",
       "  'voc': 17,\n",
       "  'cri': 19,\n",
       "  'serv': 14,\n",
       "  'quer': 12,\n",
       "  'fic': 29,\n",
       "  'dificil': 13,\n",
       "  'redefin': 14,\n",
       "  'funcion': 71,\n",
       "  'sit': 16,\n",
       "  'jeit': 11,\n",
       "  'cert': 13,\n",
       "  'ta': 17,\n",
       "  'nad': 37,\n",
       "  'problem': 17,\n",
       "  'email': 24,\n",
       "  'hor': 16,\n",
       "  'const': 12,\n",
       "  'pagin': 11,\n",
       "  'send': 14,\n",
       "  'codig': 13,\n",
       "  'vou': 20,\n",
       "  'precis': 20,\n",
       "  'inscrica': 12,\n",
       "  'enem': 21,\n",
       "  'ajud': 20,\n",
       "  'govern': 12,\n",
       "  'nov': 13,\n",
       "  'aparec': 29,\n",
       "  'algu': 11},\n",
       " 'not_usability': {'ok': 30,\n",
       "  'hh': 10,\n",
       "  'top': 20,\n",
       "  'boa': 40,\n",
       "  'bom': 340,\n",
       "  'amo': 10,\n",
       "  'gea': 10,\n",
       "  'ruim': 140,\n",
       "  'joi': 10,\n",
       "  'util': 10,\n",
       "  'zer': 10,\n",
       "  'lix': 50,\n",
       "  'otim': 140,\n",
       "  'med': 10,\n",
       "  'legal': 30,\n",
       "  'bost': 20,\n",
       "  'pecim': 10,\n",
       "  'belez': 10,\n",
       "  'inutil': 10,\n",
       "  'not': 10,\n",
       "  'mt': 10,\n",
       "  'mbbnb': 10,\n",
       "  'parabens': 20,\n",
       "  'terrivel': 10,\n",
       "  'excelent': 40,\n",
       "  'sim': 10,\n",
       "  'agil': 10,\n",
       "  'funcion': 10,\n",
       "  'satisfaz': 10,\n",
       "  'gost': 10,\n",
       "  'drog': 20,\n",
       "  'acessivel': 10,\n",
       "  'facil': 10,\n",
       "  'dem': 10,\n",
       "  'app': 60,\n",
       "  'decepcion': 10,\n",
       "  'orient': 10,\n",
       "  'profissa': 10,\n",
       "  'pront': 10,\n",
       "  'obrig': 10,\n",
       "  'servic': 10,\n",
       "  'ger': 10,\n",
       "  'naveg': 10,\n",
       "  'vcs': 10,\n",
       "  'sao': 10,\n",
       "  'fraud': 10,\n",
       "  'complet': 10,\n",
       "  'realment': 10,\n",
       "  'vo': 10,\n",
       "  'test': 10,\n",
       "  'bem': 20,\n",
       "  'bol': 10,\n",
       "  'fak': 10,\n",
       "  'cuid': 10,\n",
       "  'especial': 10,\n",
       "  'pod': 10,\n",
       "  'ser': 10,\n",
       "  'melhor': 10,\n",
       "  'consegu': 10,\n",
       "  'entrar': 10,\n",
       "  'segur': 20,\n",
       "  'hip': 10,\n",
       "  'aplic': 10,\n",
       "  'consig': 20,\n",
       "  'acess': 20,\n",
       "  'experienc': 10,\n",
       "  'tud': 10,\n",
       "  'cert': 10,\n",
       "  'rap': 10,\n",
       "  'motor': 10,\n",
       "  'categor': 10,\n",
       "  'sint': 10,\n",
       "  'noj': 10,\n",
       "  'govern': 10,\n",
       "  'carreg': 10,\n",
       "  'perfeit': 10,\n",
       "  'maravilh': 10,\n",
       "  'aprov': 10,\n",
       "  'serv': 10,\n",
       "  'nad': 10,\n",
       "  'gabrielvitor': 10,\n",
       "  'sant': 10,\n",
       "  'import': 10,\n",
       "  'mim': 10,\n",
       "  'orivel': 10,\n",
       "  'esclarecedor': 10}}"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_usa = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
