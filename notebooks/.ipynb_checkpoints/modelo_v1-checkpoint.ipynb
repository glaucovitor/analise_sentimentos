{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Augusto e Ícaro\n",
    "## Modelo de automatização das Heurísticas de Nielsen para comentários em reviews de Apps\n",
    "\n",
    "* Versão 1.0\n",
    "* Bibliotecas utilizadas: pandas, numpy, texthero, ntlk e corpus do ntlk em português\n",
    "* Dataset utilizado: dataset_v4.csv\n",
    "* Data: 22/07/2020\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "[x] Pre processamento detalhado\n",
    "\n",
    "[x] Pipeline de pre-processamento\n",
    "\n",
    "[x] Classificador baseado em ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: texthero in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.9)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.7.0)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.9.0)\n",
      "Requirement already satisfied: gensim>=3.6.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.8.3)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (2.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: nltk>=3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.5)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.1.1)\n",
      "Requirement already satisfied: tqdm>=4.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.46.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (0.23.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: pillow in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: six in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (1.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (47.3.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.7.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (7.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: boto in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.14.23)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.6.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.9)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.23 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.17.23)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.23->boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.15.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (4.46.1)\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (0.15.1)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install texthero \n",
    "!{sys.executable} -m pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import nltk\n",
    "import numpy as np\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa versão iremos testar apenas com textos em ingles, sem adicionar os pesos de sentimentos e heurísticas de Nielsen. Queremos treinar o modelo para classificar apenas em usabilidade ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negócio de reconhecimento facialnão funciona. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um lixo!!! 9 tentativas de econhecimento facia...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horrível! Pior que FBI! Se fosse pra receberem...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meio difícil fazer sem óculos mais deu certo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não serve pra nada , não dá para acessar,péssimo.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  Negócio de reconhecimento facialnão funciona. ...          True   \n",
       "1  Um lixo!!! 9 tentativas de econhecimento facia...         False   \n",
       "2  Horrível! Pior que FBI! Se fosse pra receberem...          True   \n",
       "3       Meio difícil fazer sem óculos mais deu certo          True   \n",
       "4  Não serve pra nada , não dá para acessar,péssimo.          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'is_usability', 'is_classified']\n",
    "df = pd.read_csv(\"reviews_v4.csv\", index_col=False, usecols=cols)\n",
    "df = df.rename(columns={'Text': 'text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    755\n",
       "True     175\n",
       "Name: is_usability, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    548\n",
       "True     381\n",
       "Name: is_classified, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_classified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dados\n",
    "\n",
    "O pipeline padrão remove dígitos, pontuação, remove diacritics, stopwords em inglês e whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negocio de reconhecimento facialnao funciona n...\n",
       "1      um lixo tentativas de econhecimento facial sem...\n",
       "2      horrivel pior que fbi se fosse pra receberem a...\n",
       "3           meio dificil fazer sem oculos mais deu certo\n",
       "4         nao serve pra nada nao da para acessar pessimo\n",
       "                             ...                        \n",
       "925    como eu faco pra entrar na minha conta enem pe...\n",
       "926    sim facilita muito em varios servicos e mais i...\n",
       "927    nao consigo acessar meu auxilio como faco pra ...\n",
       "928                                  seguro hiper seguro\n",
       "929    otimo porem e bom implementar novas funcionali...\n",
       "Name: text, Length: 930, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = hero.preprocessing.get_default_pipeline()\n",
    "selected_functions_indexes = [0, 1, 2, 5, 6]\n",
    "pipeline = [pipeline[i] for i in selected_functions_indexes]\n",
    "df['text'] = hero.preprocessing.clean(df['text'])\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Removendo stopwords em português com o corpus em portugês do NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negocio  reconhecimento facialnao funciona nao  pra ficar dia todo nisso nao arrumem   favor'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('portuguese')\n",
    "df['text'] = hero.remove_stopwords(df['text'], stopwords=stopwords)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negoci reconhec facialna funcion nao pra fic dia tod niss nao arrum favor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.stem(df['text'], language='portuguese')\n",
    "df['text']\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[negoci, reconhec, facialna, funcion, nao, pra...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lix, tentat, econhec, facial, exit, dur, depe...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horrivel, pior, fbi, pra, receb, algo, gent, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mei, dificil, faz, ocul, deu, cert]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nao, serv, pra, nad, nao, acess, pessim]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  [negoci, reconhec, facialna, funcion, nao, pra...          True   \n",
       "1  [lix, tentat, econhec, facial, exit, dur, depe...         False   \n",
       "2  [horrivel, pior, fbi, pra, receb, algo, gent, ...          True   \n",
       "3               [mei, dificil, faz, ocul, deu, cert]          True   \n",
       "4          [nao, serv, pra, nad, nao, acess, pessim]          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.tokenize(df['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_name'] = df.apply(lambda row: 'usability' if row['is_usability'] else 'not_usability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['negoci',\n",
       "  'reconhec',\n",
       "  'facialna',\n",
       "  'funcion',\n",
       "  'nao',\n",
       "  'pra',\n",
       "  'fic',\n",
       "  'dia',\n",
       "  'tod',\n",
       "  'niss',\n",
       "  'nao',\n",
       "  'arrum',\n",
       "  'favor'],\n",
       " 'is_classified': True,\n",
       " 'class_name': 'usability'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('is_usability', 1)\n",
    "df = df.to_dict('records')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "Nessa parte, iremos treinar e utilizar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para aprendizado dos dados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(training_data):\n",
    "    corpus_words = {}\n",
    "    for data in training_data: \n",
    "        class_name = data['class_name']\n",
    "        frase = data['text']\n",
    "        if class_name not in list(corpus_words.keys()):\n",
    "            corpus_words[class_name] = {}\n",
    "        for word in frase:\n",
    "            if word not in list(corpus_words[class_name].keys()):\n",
    "                corpus_words[class_name][word] = 1\n",
    "            else:\n",
    "                corpus_words[class_name][word] += 1\n",
    "    return corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(corpus, sentence):\n",
    "    def calculate_class_score(corpus_words, sentence, class_name):\n",
    "        score = 0 \n",
    "        for word in sentence:\n",
    "            if word in corpus_words[class_name]:\n",
    "                score += corpus_words[class_name][word]\n",
    "        return score\n",
    "    classifications = []\n",
    "    for class_name in corpus.keys():\n",
    "        classifications.append({'class_name': class_name, 'score': calculate_class_score(corpus, sentence, class_name)})    \n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para normalizar os scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(classification):\n",
    "    total_score = sum(score['score'] for score in classification['scores'])\n",
    "    if total_score != 0:\n",
    "        for score in classification['scores']:\n",
    "            score['score'] = score['score']/total_score\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função principal\n",
    "\n",
    "* Divide o dataset em classificados e não classificados.\n",
    "* Divide os classificados para teste e treino: 20% teste e 80% treino.\n",
    "* Calcula em 50 interações a média da acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Accuracy 0.5454545454545454\n",
      "Iteration 1 - Accuracy 0.6233766233766234\n",
      "Iteration 2 - Accuracy 0.5324675324675324\n",
      "Iteration 3 - Accuracy 0.6363636363636364\n",
      "Iteration 4 - Accuracy 0.6233766233766234\n",
      "Iteration 5 - Accuracy 0.5194805194805194\n",
      "Iteration 6 - Accuracy 0.5194805194805194\n",
      "Iteration 7 - Accuracy 0.4675324675324675\n",
      "Iteration 8 - Accuracy 0.5194805194805194\n",
      "Iteration 9 - Accuracy 0.6363636363636364\n",
      "Iteration 10 - Accuracy 0.6233766233766234\n",
      "Iteration 11 - Accuracy 0.6103896103896104\n",
      "Iteration 12 - Accuracy 0.5714285714285714\n",
      "Iteration 13 - Accuracy 0.5844155844155844\n",
      "Iteration 14 - Accuracy 0.5584415584415584\n",
      "Iteration 15 - Accuracy 0.5584415584415584\n",
      "Iteration 16 - Accuracy 0.5454545454545454\n",
      "Iteration 17 - Accuracy 0.4935064935064935\n",
      "Iteration 18 - Accuracy 0.6103896103896104\n",
      "Iteration 19 - Accuracy 0.6493506493506493\n",
      "Iteration 20 - Accuracy 0.4935064935064935\n",
      "Iteration 21 - Accuracy 0.5714285714285714\n",
      "Iteration 22 - Accuracy 0.5974025974025974\n",
      "Iteration 23 - Accuracy 0.5714285714285714\n",
      "Iteration 24 - Accuracy 0.6233766233766234\n",
      "Iteration 25 - Accuracy 0.6233766233766234\n",
      "Iteration 26 - Accuracy 0.5454545454545454\n",
      "Iteration 27 - Accuracy 0.5974025974025974\n",
      "Iteration 28 - Accuracy 0.5454545454545454\n",
      "Iteration 29 - Accuracy 0.5844155844155844\n",
      "Iteration 30 - Accuracy 0.4675324675324675\n",
      "Iteration 31 - Accuracy 0.5324675324675324\n",
      "Iteration 32 - Accuracy 0.6103896103896104\n",
      "Iteration 33 - Accuracy 0.4805194805194805\n",
      "Iteration 34 - Accuracy 0.5974025974025974\n",
      "Iteration 35 - Accuracy 0.6103896103896104\n",
      "Iteration 36 - Accuracy 0.6623376623376623\n",
      "Iteration 37 - Accuracy 0.5974025974025974\n",
      "Iteration 38 - Accuracy 0.5324675324675324\n",
      "Iteration 39 - Accuracy 0.5584415584415584\n",
      "Iteration 40 - Accuracy 0.6363636363636364\n",
      "Iteration 41 - Accuracy 0.6233766233766234\n",
      "Iteration 42 - Accuracy 0.6623376623376623\n",
      "Iteration 43 - Accuracy 0.6753246753246753\n",
      "Iteration 44 - Accuracy 0.5584415584415584\n",
      "Iteration 45 - Accuracy 0.5844155844155844\n",
      "Iteration 46 - Accuracy 0.5844155844155844\n",
      "Iteration 47 - Accuracy 0.6103896103896104\n",
      "Iteration 48 - Accuracy 0.7012987012987013\n",
      "Iteration 49 - Accuracy 0.5064935064935064\n",
      "-----------------\n",
      "Final accuracy 0.5794805194805195\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "classified_df = []\n",
    "unclassified_df = []\n",
    "\n",
    "for data in df:\n",
    "    classified_df.append(data) if data['is_classified'] else unclassified_df.append(data)\n",
    "\n",
    "accuracies = []\n",
    "iterations = 50\n",
    "for i in range(iterations):\n",
    "    train_dataset = []\n",
    "    test_dataset = []\n",
    "    random.shuffle(classified_df)\n",
    "    train_dataset, test_dataset = np.split(classified_df, [int(len(classified_df)*0.8)])\n",
    "    \n",
    "    corpus = learning(train_dataset)\n",
    "    classifications = [{'test_data': test_data, 'scores': classificate(corpus, test_data['text'])} for test_data in test_dataset]\n",
    "    classifications = [normalize_scores(classification) for classification in classifications]\n",
    "    \n",
    "    right_answers = 0\n",
    "    for classification in classifications:\n",
    "        higher_score = max(classification['scores'], key=lambda x:x['score'])\n",
    "        if classification['test_data']['class_name'] == higher_score['class_name']:\n",
    "            right_answers += 1\n",
    "    \n",
    "    accuracy = right_answers/len(classifications)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Iteration {i} - Accuracy {accuracy}')\n",
    "\n",
    "print('-----------------')\n",
    "print(f'Final accuracy {sum(accuracies)/len(accuracies)}')\n",
    "print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
