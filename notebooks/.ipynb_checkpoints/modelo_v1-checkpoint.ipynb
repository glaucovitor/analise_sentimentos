{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Augusto e Ícaro\n",
    "## Modelo de automatização das Heurísticas de Nielsen para comentários em reviews de Apps\n",
    "\n",
    "* Versão 1.0\n",
    "* Bibliotecas utilizadas: pandas, numpy, texthero, ntlk e corpus do ntlk em português\n",
    "* Dataset utilizado: dataset_v4.csv\n",
    "* Data: 22/07/2020\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "[x] Pre processamento detalhado\n",
    "\n",
    "[x] Pipeline de pre-processamento\n",
    "\n",
    "[x] Classificador baseado em ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: texthero in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.9)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (0.23.1)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: nltk>=3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.5)\n",
      "Requirement already satisfied: gensim>=3.6.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.8.3)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.46.1)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.1.1)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (2.3.2)\n",
      "Requirement already satisfied: six in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (0.15.1)\n",
      "Requirement already satisfied: pillow in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (2020.6.8)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (47.3.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (7.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: boto in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.14.23)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.9)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.23 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.17.23)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.23->boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.15.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.5)\r\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (0.15.1)\r\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (2020.6.8)\r\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (7.1.2)\r\n",
      "Requirement already satisfied: tqdm in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (4.46.1)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install texthero \n",
    "!{sys.executable} -m pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import nltk\n",
    "import numpy as np\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa versão iremos testar apenas com textos em ingles, sem adicionar os pesos de sentimentos e heurísticas de Nielsen. Queremos treinar o modelo para classificar apenas em usabilidade ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negócio de reconhecimento facialnão funciona. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um lixo!!! 9 tentativas de econhecimento facia...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horrível! Pior que FBI! Se fosse pra receberem...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meio difícil fazer sem óculos mais deu certo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não serve pra nada , não dá para acessar,péssimo.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  Negócio de reconhecimento facialnão funciona. ...          True   \n",
       "1  Um lixo!!! 9 tentativas de econhecimento facia...         False   \n",
       "2  Horrível! Pior que FBI! Se fosse pra receberem...          True   \n",
       "3       Meio difícil fazer sem óculos mais deu certo          True   \n",
       "4  Não serve pra nada , não dá para acessar,péssimo.          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'is_usability', 'is_classified']\n",
    "df = pd.read_csv(\"reviews_v4.csv\", index_col=False, usecols=cols)\n",
    "df = df.rename(columns={'Text': 'text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    755\n",
       "True     175\n",
       "Name: is_usability, dtype: int64"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    548\n",
       "True     381\n",
       "Name: is_classified, dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_classified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dados\n",
    "\n",
    "O pipeline padrão remove dígitos, pontuação, remove diacritics, stopwords em inglês e whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function texthero.preprocessing.fillna(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.lowercase(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_digits(input: pandas.core.series.Series, only_blocks=True) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_punctuation(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_diacritics(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_stopwords(input: pandas.core.series.Series, stopwords: Union[Set[str], NoneType] = None, remove_str_numbers=False) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_whitespace(input: pandas.core.series.Series) -> pandas.core.series.Series>]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = hero.preprocessing.get_default_pipeline()\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negocio de reconhecimento facialnao funciona n...\n",
       "1      um lixo tentativas de econhecimento facial sem...\n",
       "2      horrivel pior que fbi se fosse pra receberem a...\n",
       "3           meio dificil fazer sem oculos mais deu certo\n",
       "4         nao serve pra nada nao da para acessar pessimo\n",
       "                             ...                        \n",
       "925    como eu faco pra entrar na minha conta enem pe...\n",
       "926    sim facilita muito em varios servicos e mais i...\n",
       "927    nao consigo acessar meu auxilio como faco pra ...\n",
       "928                                  seguro hiper seguro\n",
       "929    otimo porem e bom implementar novas funcionali...\n",
       "Name: text, Length: 930, dtype: object"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_functions_indexes = [0, 1, 2, 5, 6]\n",
    "pipeline = [pipeline[i] for i in selected_functions_indexes]\n",
    "df['text'] = hero.preprocessing.clean(df['text'])\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Removendo stopwords em português com o corpus em portugês do NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negocio  reconhecimento facialnao funciona nao  pra ficar dia todo nisso nao arrumem   favor'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('portuguese')\n",
    "df['text'] = hero.remove_stopwords(df['text'], stopwords=stopwords)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negoci reconhec facialna funcion nao pra fic dia tod niss nao arrum favor'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.stem(df['text'], language='portuguese')\n",
    "df['text']\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[negoci, reconhec, facialna, funcion, nao, pra...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lix, tentat, econhec, facial, exit, dur, depe...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horrivel, pior, fbi, pra, receb, algo, gent, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mei, dificil, faz, ocul, deu, cert]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nao, serv, pra, nad, nao, acess, pessim]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  [negoci, reconhec, facialna, funcion, nao, pra...          True   \n",
       "1  [lix, tentat, econhec, facial, exit, dur, depe...         False   \n",
       "2  [horrivel, pior, fbi, pra, receb, algo, gent, ...          True   \n",
       "3               [mei, dificil, faz, ocul, deu, cert]          True   \n",
       "4          [nao, serv, pra, nad, nao, acess, pessim]          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.tokenize(df['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_name'] = df.apply(lambda row: 'usability' if row['is_usability'] else 'not_usability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['negoci',\n",
       "  'reconhec',\n",
       "  'facialna',\n",
       "  'funcion',\n",
       "  'nao',\n",
       "  'pra',\n",
       "  'fic',\n",
       "  'dia',\n",
       "  'tod',\n",
       "  'niss',\n",
       "  'nao',\n",
       "  'arrum',\n",
       "  'favor'],\n",
       " 'is_classified': True,\n",
       " 'class_name': 'usability'}"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('is_usability', 1)\n",
    "df = df.to_dict('records')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "Nessa parte, iremos treinar e utilizar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para aprendizado dos dados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(training_data):\n",
    "    corpus_words = {}\n",
    "    for data in training_data: \n",
    "        class_name = data['class_name']\n",
    "        frase = data['text']\n",
    "        if class_name not in list(corpus_words.keys()):\n",
    "            corpus_words[class_name] = {}\n",
    "        for word in frase:\n",
    "            if word not in list(corpus_words[class_name].keys()):\n",
    "                corpus_words[class_name][word] = 1\n",
    "            else:\n",
    "                corpus_words[class_name][word] += 1\n",
    "    return corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(corpus, sentence):\n",
    "    def calculate_class_score(corpus_words, sentence, class_name):\n",
    "        score = 0 \n",
    "        for word in sentence:\n",
    "            if word in corpus_words[class_name]:\n",
    "                score += corpus_words[class_name][word]\n",
    "        return score\n",
    "    classifications = []\n",
    "    for class_name in corpus.keys():\n",
    "        classifications.append({'class_name': class_name, 'score': calculate_class_score(corpus, sentence, class_name)})    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo o dataset dos classificados em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtd test 34\n",
      "qtd train 348\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "classified_df = []\n",
    "unclassified_df = []\n",
    "\n",
    "for data in df:\n",
    "    classified_df.append(data) if data['is_classified'] else unclassified_df.append(data)\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "    \n",
    "for i in classified_df:\n",
    "    r = random.uniform(0,1)\n",
    "    if r <= 0.1:\n",
    "        test_dataset.append(i)\n",
    "    else:\n",
    "        train_dataset.append(i)\n",
    "\n",
    "print(f'qtd test {len(test_dataset)}')\n",
    "print(f'qtd train {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtd usability keys 765\n",
      "qtd not_usability keys 568\n"
     ]
    }
   ],
   "source": [
    "corpus = learning(classified_df)\n",
    "print(f'qtd usability keys {len(corpus[\"usability\"].keys())}')\n",
    "print(f'qtd not_usability keys {len(corpus[\"not_usability\"].keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [{'test_data': test_data, 'scores': get_scores(corpus, test_data['text'])} for test_data in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(classification):\n",
    "    total_score = sum(score['score'] for score in classification['scores'])\n",
    "    for score in classification['scores']:\n",
    "        score['score'] = score['score']/total_score\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [normalize_scores(classification) for classification in classifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_data': {'text': ['nao',\n",
       "    'serv',\n",
       "    'pra',\n",
       "    'nad',\n",
       "    'nao',\n",
       "    'acess',\n",
       "    'pessim'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6295503211991434},\n",
       "   {'class_name': 'not_usability', 'score': 0.37044967880085655}]},\n",
       " {'test_data': {'text': ['mud',\n",
       "    'mail',\n",
       "    'inss',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'entrar',\n",
       "    'fac'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6792828685258964},\n",
       "   {'class_name': 'not_usability', 'score': 0.3207171314741036}]},\n",
       " {'test_data': {'text': ['olha',\n",
       "    'pessim',\n",
       "    'app',\n",
       "    'tent',\n",
       "    'anos',\n",
       "    'recuper',\n",
       "    'senh',\n",
       "    'nunc',\n",
       "    'consig',\n",
       "    'voc',\n",
       "    'pod',\n",
       "    'simplific',\n",
       "    'ne',\n",
       "    'aff'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6722689075630253},\n",
       "   {'class_name': 'not_usability', 'score': 0.3277310924369748}]},\n",
       " {'test_data': {'text': ['bom'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.3333333333333333},\n",
       "   {'class_name': 'not_usability', 'score': 0.6666666666666666}]},\n",
       " {'test_data': {'text': ['drog', 'app'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6176470588235294},\n",
       "   {'class_name': 'not_usability', 'score': 0.38235294117647056}]},\n",
       " {'test_data': {'text': ['quer', 'tir', 'carteir', 'trabalh'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6382978723404256},\n",
       "   {'class_name': 'not_usability', 'score': 0.3617021276595745}]},\n",
       " {'test_data': {'text': ['erro', 'reconhec', 'facial'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6602564102564102},\n",
       "   {'class_name': 'not_usability', 'score': 0.33974358974358976}]},\n",
       " {'test_data': {'text': ['dificil',\n",
       "    'faz',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'ja',\n",
       "    'tent',\n",
       "    'umas',\n",
       "    'vez',\n",
       "    'temp',\n",
       "    'nao',\n",
       "    'pra',\n",
       "    'conclu'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6746666666666666},\n",
       "   {'class_name': 'not_usability', 'score': 0.3253333333333333}]},\n",
       " {'test_data': {'text': ['aplic',\n",
       "    'ruim',\n",
       "    'lent',\n",
       "    'nao',\n",
       "    'conseg',\n",
       "    'identific',\n",
       "    'reconhec',\n",
       "    'facial'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6227436823104693},\n",
       "   {'class_name': 'not_usability', 'score': 0.37725631768953066}]},\n",
       " {'test_data': {'text': ['cpf',\n",
       "    'mail',\n",
       "    'assoc',\n",
       "    'nunc',\n",
       "    'use',\n",
       "    'pra',\n",
       "    'redefin',\n",
       "    'senh',\n",
       "    'quas',\n",
       "    'impossivel',\n",
       "    'dao',\n",
       "    'opco',\n",
       "    'banc',\n",
       "    'validaca',\n",
       "    'cnh',\n",
       "    'nenhum',\n",
       "    'funcion',\n",
       "    'pessim'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6428571428571429},\n",
       "   {'class_name': 'not_usability', 'score': 0.35714285714285715}]},\n",
       " {'test_data': {'text': ['nao',\n",
       "    'consegu',\n",
       "    'recuper',\n",
       "    'senh',\n",
       "    'ruim',\n",
       "    'program'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.653558052434457},\n",
       "   {'class_name': 'not_usability', 'score': 0.3464419475655431}]},\n",
       " {'test_data': {'text': ['esquec',\n",
       "    'senh',\n",
       "    'opca',\n",
       "    'esquec',\n",
       "    'senh',\n",
       "    'nao',\n",
       "    'aparec',\n",
       "    'mail',\n",
       "    'telefon',\n",
       "    'fac'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.7017543859649122},\n",
       "   {'class_name': 'not_usability', 'score': 0.2982456140350877}]},\n",
       " {'test_data': {'text': ['pessim', 'horrivel', 'work'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.42696629213483145},\n",
       "   {'class_name': 'not_usability', 'score': 0.5730337078651685}]},\n",
       " {'test_data': {'text': ['app', 'ruim', 'n', 'aconselh', 'ningu', 'ussar'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.5555555555555556},\n",
       "   {'class_name': 'not_usability', 'score': 0.4444444444444444}]},\n",
       " {'test_data': {'text': ['nao',\n",
       "    'consig',\n",
       "    'cadastr',\n",
       "    'onde',\n",
       "    'acho',\n",
       "    'numer',\n",
       "    'cadastr'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6578947368421053},\n",
       "   {'class_name': 'not_usability', 'score': 0.34210526315789475}]},\n",
       " {'test_data': {'text': ['deus',\n",
       "    'nao',\n",
       "    'conseg',\n",
       "    'faz',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'cois',\n",
       "    'ja',\n",
       "    'sao',\n",
       "    'tao',\n",
       "    'dific',\n",
       "    'aind',\n",
       "    'dificult',\n",
       "    'vid',\n",
       "    'cidada'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6661417322834645},\n",
       "   {'class_name': 'not_usability', 'score': 0.33385826771653543}]},\n",
       " {'test_data': {'text': ['ped',\n",
       "    'pra',\n",
       "    'faz',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'parec',\n",
       "    'ridicul',\n",
       "    'orientaco',\n",
       "    'aparec',\n",
       "    'tel',\n",
       "    'lid',\n",
       "    'temp',\n",
       "    'orient',\n",
       "    'fech',\n",
       "    'olhos',\n",
       "    'vir',\n",
       "    'rost',\n",
       "    'lad',\n",
       "    'bol',\n",
       "    'tent',\n",
       "    'var',\n",
       "    'vez',\n",
       "    'impossivel',\n",
       "    'ped',\n",
       "    'ajud',\n",
       "    'algu',\n",
       "    'ler',\n",
       "    'tel',\n",
       "    'temp',\n",
       "    'sempr',\n",
       "    'espir',\n",
       "    'antes',\n",
       "    'conclu',\n",
       "    'ridicul'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.7117437722419929},\n",
       "   {'class_name': 'not_usability', 'score': 0.28825622775800713}]},\n",
       " {'test_data': {'text': ['boa'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.375},\n",
       "   {'class_name': 'not_usability', 'score': 0.625}]},\n",
       " {'test_data': {'text': ['funcion',\n",
       "    'tent',\n",
       "    'realiz',\n",
       "    'cadastr',\n",
       "    'receb',\n",
       "    'mensag',\n",
       "    'ja',\n",
       "    'exist',\n",
       "    'nunc',\n",
       "    'use',\n",
       "    'ap'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6753246753246753},\n",
       "   {'class_name': 'not_usability', 'score': 0.3246753246753247}]},\n",
       " {'test_data': {'text': ['digit',\n",
       "    'cpf',\n",
       "    'nao',\n",
       "    'dao',\n",
       "    'opco',\n",
       "    'nom',\n",
       "    'mae',\n",
       "    'dat',\n",
       "    'nasciment',\n",
       "    'corret',\n",
       "    'conform',\n",
       "    'document'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.639618138424821},\n",
       "   {'class_name': 'not_usability', 'score': 0.360381861575179}]},\n",
       " {'test_data': {'text': ['duv',\n",
       "    'pior',\n",
       "    'experienc',\n",
       "    'ja',\n",
       "    'aplic',\n",
       "    'feit',\n",
       "    'ser',\n",
       "    'irracion',\n",
       "    'pod',\n",
       "    'alem',\n",
       "    'tud',\n",
       "    'descriminatori',\n",
       "    'exig',\n",
       "    'tir',\n",
       "    'ocul',\n",
       "    'tir',\n",
       "    'fot',\n",
       "    'angul',\n",
       "    'necessari',\n",
       "    'ler',\n",
       "    'tel',\n",
       "    'comand',\n",
       "    'pesso',\n",
       "    'usa',\n",
       "    'ocul',\n",
       "    'porqu',\n",
       "    'precis',\n",
       "    'pra',\n",
       "    'ler'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6153846153846154},\n",
       "   {'class_name': 'not_usability', 'score': 0.38461538461538464}]},\n",
       " {'test_data': {'text': ['gent',\n",
       "    'amor',\n",
       "    'deus',\n",
       "    'nao',\n",
       "    'ia',\n",
       "    'dar',\n",
       "    'not',\n",
       "    'nenhum',\n",
       "    'deix',\n",
       "    'estrel',\n",
       "    'pra',\n",
       "    'ver',\n",
       "    'vcs',\n",
       "    'melhor',\n",
       "    'tal',\n",
       "    'reconhec',\n",
       "    'facial',\n",
       "    'fiqu',\n",
       "    'hor',\n",
       "    'olhand',\n",
       "    'pra',\n",
       "    'cam',\n",
       "    'nao',\n",
       "    'consegu',\n",
       "    'nad'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6524822695035462},\n",
       "   {'class_name': 'not_usability', 'score': 0.3475177304964539}]},\n",
       " {'test_data': {'text': ['parabens',\n",
       "    'imediat',\n",
       "    'respost',\n",
       "    'hilari',\n",
       "    'pitoresc',\n",
       "    'estapafurd',\n",
       "    'diversa',\n",
       "    'garant',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'par',\n",
       "    'rir',\n",
       "    'reconhec',\n",
       "    'facial',\n",
       "    'divert',\n",
       "    'lembr',\n",
       "    'grav',\n",
       "    'vid',\n",
       "    'compartilh',\n",
       "    'alegr'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6320132013201321},\n",
       "   {'class_name': 'not_usability', 'score': 0.367986798679868}]},\n",
       " {'test_data': {'text': ['sempr',\n",
       "    'aplic',\n",
       "    'trabalh',\n",
       "    'vez',\n",
       "    'resolv',\n",
       "    'problem'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6475409836065574},\n",
       "   {'class_name': 'not_usability', 'score': 0.3524590163934426}]},\n",
       " {'test_data': {'text': ['nao',\n",
       "    'consig',\n",
       "    'entrar',\n",
       "    'aplic',\n",
       "    'pois',\n",
       "    'diz',\n",
       "    'pra',\n",
       "    'digit',\n",
       "    'senh',\n",
       "    'nunc',\n",
       "    'fiz',\n",
       "    'senh',\n",
       "    'algum',\n",
       "    'dai',\n",
       "    'tent',\n",
       "    'recuper',\n",
       "    'senh',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'pois',\n",
       "    'numer',\n",
       "    'telefon',\n",
       "    'pra',\n",
       "    'ser',\n",
       "    'envi',\n",
       "    'mensag',\n",
       "    'recuperaca',\n",
       "    'senh',\n",
       "    'nao',\n",
       "    'numer',\n",
       "    'ai',\n",
       "    'fic',\n",
       "    'dificil',\n",
       "    'viu',\n",
       "    'ache',\n",
       "    'pessim',\n",
       "    'pois',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'acess',\n",
       "    'form',\n",
       "    'algum'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.67044208987943},\n",
       "   {'class_name': 'not_usability', 'score': 0.32955791012056995}]},\n",
       " {'test_data': {'text': ['seri',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'entrar',\n",
       "    'aplic',\n",
       "    'ja',\n",
       "    'seman',\n",
       "    'porqu',\n",
       "    'ped',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'fac',\n",
       "    'tod',\n",
       "    'proced',\n",
       "    'duas',\n",
       "    'tres',\n",
       "    'quatr',\n",
       "    'vez',\n",
       "    'repet',\n",
       "    'nad',\n",
       "    'enta',\n",
       "    'quer',\n",
       "    'diz',\n",
       "    'perd',\n",
       "    'tud'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6738868832731648},\n",
       "   {'class_name': 'not_usability', 'score': 0.32611311672683513}]},\n",
       " {'test_data': {'text': ['nao', 'funcionacom', 'rost'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6512261580381471},\n",
       "   {'class_name': 'not_usability', 'score': 0.34877384196185285}]},\n",
       " {'test_data': {'text': ['possivel',\n",
       "    'faz',\n",
       "    'biometr',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'entretant',\n",
       "    'nao',\n",
       "    'saiu',\n",
       "    'comprov',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'faz',\n",
       "    'ter',\n",
       "    'certez',\n",
       "    'realiz',\n",
       "    'nao',\n",
       "    'problem',\n",
       "    'inss'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6575984990619137},\n",
       "   {'class_name': 'not_usability', 'score': 0.3424015009380863}]},\n",
       " {'test_data': {'text': ['aplic',\n",
       "    'ruim',\n",
       "    'nao',\n",
       "    'consig',\n",
       "    'faz',\n",
       "    'verificaca',\n",
       "    'facil',\n",
       "    'dias',\n",
       "    'tent',\n",
       "    'entrar',\n",
       "    'dia',\n",
       "    'q',\n",
       "    'cert',\n",
       "    'entrar',\n",
       "    'verificaca',\n",
       "    'facil',\n",
       "    'fic',\n",
       "    'quas',\n",
       "    'hor',\n",
       "    'tent',\n",
       "    'tir',\n",
       "    'fot',\n",
       "    'nao',\n",
       "    'jeit',\n",
       "    'nenhum',\n",
       "    'cnh',\n",
       "    'assim',\n",
       "    'nao',\n",
       "    'dar',\n",
       "    'faz',\n",
       "    'precis',\n",
       "    'ajud'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6753387533875339},\n",
       "   {'class_name': 'not_usability', 'score': 0.32466124661246615}]},\n",
       " {'test_data': {'text': ['ide',\n",
       "    'boa',\n",
       "    'prov',\n",
       "    'vid',\n",
       "    'faz',\n",
       "    'palhac',\n",
       "    'uns',\n",
       "    '40min',\n",
       "    'n',\n",
       "    'funcion',\n",
       "    'fic',\n",
       "    'dand',\n",
       "    'erro',\n",
       "    'final'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6728395061728395},\n",
       "   {'class_name': 'not_usability', 'score': 0.3271604938271605}]},\n",
       " {'test_data': {'text': ['ajud',\n",
       "    'recuper',\n",
       "    'senh',\n",
       "    'nao',\n",
       "    'comig',\n",
       "    'entrar',\n",
       "    'cont'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6841155234657039},\n",
       "   {'class_name': 'not_usability', 'score': 0.315884476534296}]},\n",
       " {'test_data': {'text': ['nao',\n",
       "    'consig',\n",
       "    'imprim',\n",
       "    'bolet',\n",
       "    'faz',\n",
       "    'enem',\n",
       "    'inscrev',\n",
       "    'dia',\n",
       "    'nad',\n",
       "    'dess',\n",
       "    'bolet',\n",
       "    'tent',\n",
       "    'cadastr',\n",
       "    'outr',\n",
       "    'numer',\n",
       "    'oqu',\n",
       "    'fac',\n",
       "    'cas',\n",
       "    'contrari',\n",
       "    'nao',\n",
       "    'vou',\n",
       "    'consegu',\n",
       "    'faz',\n",
       "    'enem'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6648394675019577},\n",
       "   {'class_name': 'not_usability', 'score': 0.3351605324980423}]},\n",
       " {'test_data': {'text': ['app',\n",
       "    'pessim',\n",
       "    'precis',\n",
       "    'urgent',\n",
       "    'carr',\n",
       "    'tent',\n",
       "    'entrar',\n",
       "    'app',\n",
       "    'diz',\n",
       "    'ja',\n",
       "    'cadastr',\n",
       "    'poss',\n",
       "    'afirm',\n",
       "    'nunc',\n",
       "    'fiz',\n",
       "    'ai',\n",
       "    'vou',\n",
       "    'aba',\n",
       "    'recuper',\n",
       "    'senh',\n",
       "    'opco',\n",
       "    'nenhum',\n",
       "    'confer',\n",
       "    'dad',\n",
       "    'email',\n",
       "    'numer',\n",
       "    'telefon',\n",
       "    'parec',\n",
       "    'app',\n",
       "    'nao',\n",
       "    'segur',\n",
       "    'outr',\n",
       "    'pesso',\n",
       "    'cri',\n",
       "    'cont',\n",
       "    'cpf',\n",
       "    'tent',\n",
       "    'divers',\n",
       "    'vez',\n",
       "    'envi',\n",
       "    'email',\n",
       "    'respost',\n",
       "    'sempr',\n",
       "    'vem',\n",
       "    'automat',\n",
       "    'nenhum',\n",
       "    'soluca'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6841736694677871},\n",
       "   {'class_name': 'not_usability', 'score': 0.3158263305322129}]},\n",
       " {'test_data': {'text': ['nao',\n",
       "    'consegu',\n",
       "    'acess',\n",
       "    'aplic',\n",
       "    'coloc',\n",
       "    'celul',\n",
       "    'pra',\n",
       "    'ler',\n",
       "    'cod',\n",
       "    'inform',\n",
       "    'erro'],\n",
       "   'is_classified': True,\n",
       "   'class_name': 'not_usability'},\n",
       "  'scores': [{'class_name': 'usability', 'score': 0.6412213740458015},\n",
       "   {'class_name': 'not_usability', 'score': 0.35877862595419846}]}]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 - Has: usability - 0.6295503211991434 and  not_usability - 0.37044967880085655 and original result is: usability\n",
      "Test 1 - Has: usability - 0.6792828685258964 and  not_usability - 0.3207171314741036 and original result is: usability\n",
      "Test 2 - Has: usability - 0.6722689075630253 and  not_usability - 0.3277310924369748 and original result is: usability\n",
      "Test 3 - Has: usability - 0.3333333333333333 and  not_usability - 0.6666666666666666 and original result is: not_usability\n",
      "Test 4 - Has: usability - 0.6176470588235294 and  not_usability - 0.38235294117647056 and original result is: not_usability\n",
      "Test 5 - Has: usability - 0.6382978723404256 and  not_usability - 0.3617021276595745 and original result is: not_usability\n",
      "Test 6 - Has: usability - 0.6602564102564102 and  not_usability - 0.33974358974358976 and original result is: usability\n",
      "Test 7 - Has: usability - 0.6746666666666666 and  not_usability - 0.3253333333333333 and original result is: usability\n",
      "Test 8 - Has: usability - 0.6227436823104693 and  not_usability - 0.37725631768953066 and original result is: usability\n",
      "Test 9 - Has: usability - 0.6428571428571429 and  not_usability - 0.35714285714285715 and original result is: usability\n",
      "Test 10 - Has: usability - 0.653558052434457 and  not_usability - 0.3464419475655431 and original result is: usability\n",
      "Test 11 - Has: usability - 0.7017543859649122 and  not_usability - 0.2982456140350877 and original result is: usability\n",
      "Test 12 - Has: usability - 0.42696629213483145 and  not_usability - 0.5730337078651685 and original result is: not_usability\n",
      "Test 13 - Has: usability - 0.5555555555555556 and  not_usability - 0.4444444444444444 and original result is: not_usability\n",
      "Test 14 - Has: usability - 0.6578947368421053 and  not_usability - 0.34210526315789475 and original result is: usability\n",
      "Test 15 - Has: usability - 0.6661417322834645 and  not_usability - 0.33385826771653543 and original result is: usability\n",
      "Test 16 - Has: usability - 0.7117437722419929 and  not_usability - 0.28825622775800713 and original result is: usability\n",
      "Test 17 - Has: usability - 0.375 and  not_usability - 0.625 and original result is: not_usability\n",
      "Test 18 - Has: usability - 0.6753246753246753 and  not_usability - 0.3246753246753247 and original result is: not_usability\n",
      "Test 19 - Has: usability - 0.639618138424821 and  not_usability - 0.360381861575179 and original result is: not_usability\n",
      "Test 20 - Has: usability - 0.6153846153846154 and  not_usability - 0.38461538461538464 and original result is: not_usability\n",
      "Test 21 - Has: usability - 0.6524822695035462 and  not_usability - 0.3475177304964539 and original result is: usability\n",
      "Test 22 - Has: usability - 0.6320132013201321 and  not_usability - 0.367986798679868 and original result is: not_usability\n",
      "Test 23 - Has: usability - 0.6475409836065574 and  not_usability - 0.3524590163934426 and original result is: not_usability\n",
      "Test 24 - Has: usability - 0.67044208987943 and  not_usability - 0.32955791012056995 and original result is: usability\n",
      "Test 25 - Has: usability - 0.6738868832731648 and  not_usability - 0.32611311672683513 and original result is: usability\n",
      "Test 26 - Has: usability - 0.6512261580381471 and  not_usability - 0.34877384196185285 and original result is: not_usability\n",
      "Test 27 - Has: usability - 0.6575984990619137 and  not_usability - 0.3424015009380863 and original result is: usability\n",
      "Test 28 - Has: usability - 0.6753387533875339 and  not_usability - 0.32466124661246615 and original result is: usability\n",
      "Test 29 - Has: usability - 0.6728395061728395 and  not_usability - 0.3271604938271605 and original result is: usability\n",
      "Test 30 - Has: usability - 0.6841155234657039 and  not_usability - 0.315884476534296 and original result is: usability\n",
      "Test 31 - Has: usability - 0.6648394675019577 and  not_usability - 0.3351605324980423 and original result is: usability\n",
      "Test 32 - Has: usability - 0.6841736694677871 and  not_usability - 0.3158263305322129 and original result is: usability\n",
      "Test 33 - Has: usability - 0.6412213740458015 and  not_usability - 0.35877862595419846 and original result is: not_usability\n"
     ]
    }
   ],
   "source": [
    "for i, classification in enumerate(classifications):\n",
    "    message = \"\"\n",
    "    message = message + f'Test {i} - Has:'\n",
    "    for score in classification['scores']:\n",
    "        message = message + \" \" + score['class_name'] + \" - \" + str(score['score'])  + \" and \"\n",
    "    message = message + \"original result is: \" + classification['test_data']['class_name']\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, classification in enumerate(classifications):\n",
    "    higher = max(c , key=lambda x:x['price'])\n",
    "    print(higher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
