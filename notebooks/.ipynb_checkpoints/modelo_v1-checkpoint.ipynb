{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC Augusto e Ícaro\n",
    "## Modelo de automatização das Heurísticas de Nielsen para comentários em reviews de Apps\n",
    "\n",
    "* Versão 1.0\n",
    "* Bibliotecas utilizadas: pandas, numpy, texthero, ntlk e corpus do ntlk em português\n",
    "* Dataset utilizado: dataset_v4.csv\n",
    "* Data: 22/07/2020\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "[x] Pre processamento detalhado\n",
    "\n",
    "[x] Pipeline de pre-processamento\n",
    "\n",
    "[x] Classificador baseado em ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.18.5)\n",
      "Requirement already satisfied: texthero in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (1.0.9)\n",
      "Requirement already satisfied: nltk>=3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.5)\n",
      "Requirement already satisfied: tqdm>=4.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.46.1)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: gensim>=3.6.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.8.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (0.23.1)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (2.3.2)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (1.1.1)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (4.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (0.15.1)\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from gensim>=3.6.0->texthero) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (2.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.7.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (47.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: pillow in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: boto in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.14.23)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.4.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.6.1)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.23 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (1.17.23)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.23->boto3->smart-open>=1.8.1->gensim>=3.6.0->texthero) (0.15.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (3.5)\r\n",
      "Requirement already satisfied: regex in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (2020.6.8)\r\n",
      "Requirement already satisfied: joblib in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (0.15.1)\r\n",
      "Requirement already satisfied: tqdm in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (4.46.1)\r\n",
      "Requirement already satisfied: click in /home/icaro/.pyenv/versions/3.7.3/lib/python3.7/site-packages (from nltk) (7.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install texthero \n",
    "!{sys.executable} -m pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import texthero as hero\n",
    "import nltk\n",
    "import numpy as np\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa versão iremos testar apenas com textos em ingles, sem adicionar os pesos de sentimentos e heurísticas de Nielsen. Queremos treinar o modelo para classificar apenas em usabilidade ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negócio de reconhecimento facialnão funciona. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um lixo!!! 9 tentativas de econhecimento facia...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horrível! Pior que FBI! Se fosse pra receberem...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meio difícil fazer sem óculos mais deu certo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não serve pra nada , não dá para acessar,péssimo.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  Negócio de reconhecimento facialnão funciona. ...          True   \n",
       "1  Um lixo!!! 9 tentativas de econhecimento facia...         False   \n",
       "2  Horrível! Pior que FBI! Se fosse pra receberem...          True   \n",
       "3       Meio difícil fazer sem óculos mais deu certo          True   \n",
       "4  Não serve pra nada , não dá para acessar,péssimo.          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'is_usability', 'is_classified']\n",
    "df = pd.read_csv(\"reviews_v4.csv\", index_col=False, usecols=cols)\n",
    "df = df.rename(columns={'Text': 'text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    755\n",
       "True     175\n",
       "Name: is_usability, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_usability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    548\n",
       "True     381\n",
       "Name: is_classified, dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_classified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dados\n",
    "\n",
    "O pipeline padrão remove dígitos, pontuação, remove diacritics, stopwords em inglês e whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function texthero.preprocessing.fillna(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.lowercase(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_digits(input: pandas.core.series.Series, only_blocks=True) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_punctuation(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_diacritics(input: pandas.core.series.Series) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_stopwords(input: pandas.core.series.Series, stopwords: Union[Set[str], NoneType] = None, remove_str_numbers=False) -> pandas.core.series.Series>,\n",
       " <function texthero.preprocessing.remove_whitespace(input: pandas.core.series.Series) -> pandas.core.series.Series>]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = hero.preprocessing.get_default_pipeline()\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negocio de reconhecimento facialnao funciona n...\n",
       "1      um lixo tentativas de econhecimento facial sem...\n",
       "2      horrivel pior que fbi se fosse pra receberem a...\n",
       "3           meio dificil fazer sem oculos mais deu certo\n",
       "4         nao serve pra nada nao da para acessar pessimo\n",
       "                             ...                        \n",
       "925    como eu faco pra entrar na minha conta enem pe...\n",
       "926    sim facilita muito em varios servicos e mais i...\n",
       "927    nao consigo acessar meu auxilio como faco pra ...\n",
       "928                                  seguro hiper seguro\n",
       "929    otimo porem e bom implementar novas funcionali...\n",
       "Name: text, Length: 930, dtype: object"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_functions_indexes = [0, 1, 2, 5, 6]\n",
    "pipeline = [pipeline[i] for i in selected_functions_indexes]\n",
    "df['text'] = hero.preprocessing.clean(df['text'])\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Removendo stopwords em português com o corpus em portugês do NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negocio  reconhecimento facialnao funciona nao  pra ficar dia todo nisso nao arrumem   favor'"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('portuguese')\n",
    "df['text'] = hero.remove_stopwords(df['text'], stopwords=stopwords)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negoci reconhec facialna funcion nao pra fic dia tod niss nao arrum favor'"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.stem(df['text'], language='portuguese')\n",
    "df['text']\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_usability</th>\n",
       "      <th>is_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[negoci, reconhec, facialna, funcion, nao, pra...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lix, tentat, econhec, facial, exit, dur, depe...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horrivel, pior, fbi, pra, receb, algo, gent, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mei, dificil, faz, ocul, deu, cert]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nao, serv, pra, nad, nao, acess, pessim]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_usability  \\\n",
       "0  [negoci, reconhec, facialna, funcion, nao, pra...          True   \n",
       "1  [lix, tentat, econhec, facial, exit, dur, depe...         False   \n",
       "2  [horrivel, pior, fbi, pra, receb, algo, gent, ...          True   \n",
       "3               [mei, dificil, faz, ocul, deu, cert]          True   \n",
       "4          [nao, serv, pra, nad, nao, acess, pessim]          True   \n",
       "\n",
       "  is_classified  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = hero.tokenize(df['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_name'] = df.apply(lambda row: 'usability' if row['is_usability'] else 'not_usability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['negoci',\n",
       "  'reconhec',\n",
       "  'facialna',\n",
       "  'funcion',\n",
       "  'nao',\n",
       "  'pra',\n",
       "  'fic',\n",
       "  'dia',\n",
       "  'tod',\n",
       "  'niss',\n",
       "  'nao',\n",
       "  'arrum',\n",
       "  'favor'],\n",
       " 'is_classified': True,\n",
       " 'class_name': 'usability'}"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('is_usability', 1)\n",
    "df = df.to_dict('records')\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "Nessa parte, iremos treinar e utilizar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para aprendizado dos dados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(training_data):\n",
    "    corpus_words = {}\n",
    "    for data in training_data: \n",
    "        class_name = data['class_name']\n",
    "        frase = data['text']\n",
    "        if class_name not in list(corpus_words.keys()):\n",
    "            corpus_words[class_name] = {}\n",
    "        for word in frase:\n",
    "            if word not in list(corpus_words[class_name].keys()):\n",
    "                corpus_words[class_name][word] = 1\n",
    "            else:\n",
    "                corpus_words[class_name][word] += 1\n",
    "    return corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para calcular scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(corpus, sentence):\n",
    "    def calculate_class_score(corpus_words, sentence, class_name):\n",
    "        score = 0 \n",
    "        for word in sentence:\n",
    "            if word in corpus_words[class_name]:\n",
    "                score += corpus_words[class_name][word]\n",
    "        return score\n",
    "    classifications = []\n",
    "    for class_name in corpus.keys():\n",
    "        classifications.append({'class_name': class_name, 'score': calculate_class_score(corpus, sentence, class_name)})    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para normalizar os scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(classification):\n",
    "    total_score = sum(score['score'] for score in classification['scores'])\n",
    "    for score in classification['scores']:\n",
    "        score['score'] = score['score']/total_score\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo o dataset dos classificados em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test cases 79\n",
      "Total train cases 303\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "classified_df = []\n",
    "unclassified_df = []\n",
    "\n",
    "for data in df:\n",
    "    classified_df.append(data) if data['is_classified'] else unclassified_df.append(data)\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "    \n",
    "for i in classified_df:\n",
    "    r = random.uniform(0,1)\n",
    "    if r <= 0.2:\n",
    "        test_dataset.append(i)\n",
    "    else:\n",
    "        train_dataset.append(i)\n",
    "\n",
    "print(f'Total test cases {len(test_dataset)}')\n",
    "print(f'Total train cases {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtd usability keys 765\n",
      "qtd not_usability keys 568\n"
     ]
    }
   ],
   "source": [
    "corpus = learning(classified_df)\n",
    "print(f'qtd usability keys {len(corpus[\"usability\"].keys())}')\n",
    "print(f'qtd not_usability keys {len(corpus[\"not_usability\"].keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [{'test_data': test_data, 'scores': get_scores(corpus, test_data['text'])} for test_data in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_data': {'text': ['mei', 'dificil', 'faz', 'ocul', 'deu', 'cert'],\n",
       "  'is_classified': True,\n",
       "  'class_name': 'usability'},\n",
       " 'scores': [{'class_name': 'usability', 'score': 0.6691729323308271},\n",
       "  {'class_name': 'not_usability', 'score': 0.3308270676691729}]}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = [normalize_scores(classification) for classification in classifications]\n",
    "classifications[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 - Has: usability - 0.6691729323308271 and  not_usability - 0.3308270676691729 and original result is: usability\n",
      "Test 1 - Has: usability - 0.0 and  not_usability - 1.0 and original result is: not_usability\n",
      "Test 2 - Has: usability - 0.5489130434782609 and  not_usability - 0.45108695652173914 and original result is: not_usability\n",
      "Test 3 - Has: usability - 0.7586206896551724 and  not_usability - 0.2413793103448276 and original result is: usability\n",
      "Test 4 - Has: usability - 0.25 and  not_usability - 0.75 and original result is: not_usability\n",
      "Test 5 - Has: usability - 0.6613128491620112 and  not_usability - 0.33868715083798884 and original result is: usability\n",
      "Test 6 - Has: usability - 0.6694677871148459 and  not_usability - 0.33053221288515405 and original result is: usability\n",
      "Test 7 - Has: usability - 0.45302013422818793 and  not_usability - 0.5469798657718121 and original result is: not_usability\n",
      "Test 8 - Has: usability - 0.6563380281690141 and  not_usability - 0.3436619718309859 and original result is: usability\n",
      "Test 9 - Has: usability - 0.6451612903225806 and  not_usability - 0.3548387096774194 and original result is: usability\n",
      "Test 10 - Has: usability - 0.6284403669724771 and  not_usability - 0.37155963302752293 and original result is: usability\n",
      "Test 11 - Has: usability - 0.6538049303322615 and  not_usability - 0.3461950696677385 and original result is: usability\n",
      "Test 12 - Has: usability - 0.3333333333333333 and  not_usability - 0.6666666666666666 and original result is: not_usability\n",
      "Test 13 - Has: usability - 0.6589147286821705 and  not_usability - 0.34108527131782945 and original result is: usability\n",
      "Test 14 - Has: usability - 0.5897435897435898 and  not_usability - 0.41025641025641024 and original result is: not_usability\n",
      "Test 15 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 16 - Has: usability - 0.6524590163934426 and  not_usability - 0.3475409836065574 and original result is: usability\n",
      "Test 17 - Has: usability - 0.6652719665271967 and  not_usability - 0.33472803347280333 and original result is: usability\n",
      "Test 18 - Has: usability - 0.6322089227421109 and  not_usability - 0.367791077257889 and original result is: not_usability\n",
      "Test 19 - Has: usability - 0.6624203821656051 and  not_usability - 0.3375796178343949 and original result is: usability\n",
      "Test 20 - Has: usability - 0.6506024096385542 and  not_usability - 0.3493975903614458 and original result is: usability\n",
      "Test 21 - Has: usability - 0.6658986175115207 and  not_usability - 0.33410138248847926 and original result is: usability\n",
      "Test 22 - Has: usability - 0.6478190630048465 and  not_usability - 0.35218093699515346 and original result is: usability\n",
      "Test 23 - Has: usability - 0.6575342465753424 and  not_usability - 0.3424657534246575 and original result is: not_usability\n",
      "Test 24 - Has: usability - 0.6457319770013269 and  not_usability - 0.35426802299867316 and original result is: usability\n",
      "Test 25 - Has: usability - 0.6929955290611028 and  not_usability - 0.30700447093889716 and original result is: usability\n",
      "Test 26 - Has: usability - 0.6227436823104693 and  not_usability - 0.37725631768953066 and original result is: usability\n",
      "Test 27 - Has: usability - 0.6618421052631579 and  not_usability - 0.3381578947368421 and original result is: usability\n",
      "Test 28 - Has: usability - 0.6255060728744939 and  not_usability - 0.37449392712550605 and original result is: usability\n",
      "Test 29 - Has: usability - 0.6 and  not_usability - 0.4 and original result is: usability\n",
      "Test 30 - Has: usability - 0.680259499536608 and  not_usability - 0.31974050046339203 and original result is: usability\n",
      "Test 31 - Has: usability - 0.653558052434457 and  not_usability - 0.3464419475655431 and original result is: usability\n",
      "Test 32 - Has: usability - 0.6451612903225806 and  not_usability - 0.3548387096774194 and original result is: not_usability\n",
      "Test 33 - Has: usability - 0.6685796269727403 and  not_usability - 0.3314203730272597 and original result is: usability\n",
      "Test 34 - Has: usability - 0.6331811263318112 and  not_usability - 0.3668188736681887 and original result is: not_usability\n",
      "Test 35 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 36 - Has: usability - 0.5578947368421052 and  not_usability - 0.4421052631578947 and original result is: not_usability\n",
      "Test 37 - Has: usability - 0.6577400391900718 and  not_usability - 0.34225996080992815 and original result is: usability\n",
      "Test 38 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 39 - Has: usability - 0.6093457943925233 and  not_usability - 0.39065420560747666 and original result is: not_usability\n",
      "Test 40 - Has: usability - 0.6844547563805105 and  not_usability - 0.31554524361948955 and original result is: usability\n",
      "Test 41 - Has: usability - 0.375 and  not_usability - 0.625 and original result is: not_usability\n",
      "Test 42 - Has: usability - 0.627906976744186 and  not_usability - 0.37209302325581395 and original result is: usability\n",
      "Test 43 - Has: usability - 0.6447944006999126 and  not_usability - 0.3552055993000875 and original result is: not_usability\n",
      "Test 44 - Has: usability - 0.5882352941176471 and  not_usability - 0.4117647058823529 and original result is: not_usability\n",
      "Test 45 - Has: usability - 0.3333333333333333 and  not_usability - 0.6666666666666666 and original result is: not_usability\n",
      "Test 46 - Has: usability - 0.5454545454545454 and  not_usability - 0.45454545454545453 and original result is: not_usability\n",
      "Test 47 - Has: usability - 0.6096654275092936 and  not_usability - 0.3903345724907063 and original result is: not_usability\n",
      "Test 48 - Has: usability - 0.16666666666666666 and  not_usability - 0.8333333333333334 and original result is: not_usability\n",
      "Test 49 - Has: usability - 0.6591478696741855 and  not_usability - 0.3408521303258145 and original result is: usability\n",
      "Test 50 - Has: usability - 0.6403846153846153 and  not_usability - 0.3596153846153846 and original result is: not_usability\n",
      "Test 51 - Has: usability - 0.639618138424821 and  not_usability - 0.360381861575179 and original result is: not_usability\n",
      "Test 52 - Has: usability - 0.611764705882353 and  not_usability - 0.38823529411764707 and original result is: not_usability\n",
      "Test 53 - Has: usability - 0.6491372226787182 and  not_usability - 0.35086277732128185 and original result is: not_usability\n",
      "Test 54 - Has: usability - 0.3333333333333333 and  not_usability - 0.6666666666666666 and original result is: not_usability\n",
      "Test 55 - Has: usability - 0.6153846153846154 and  not_usability - 0.38461538461538464 and original result is: not_usability\n",
      "Test 56 - Has: usability - 0.6524822695035462 and  not_usability - 0.3475177304964539 and original result is: usability\n",
      "Test 57 - Has: usability - 0.5896551724137931 and  not_usability - 0.4103448275862069 and original result is: not_usability\n",
      "Test 58 - Has: usability - 0.6443298969072165 and  not_usability - 0.3556701030927835 and original result is: not_usability\n",
      "Test 59 - Has: usability - 0.4444444444444444 and  not_usability - 0.5555555555555556 and original result is: not_usability\n",
      "Test 60 - Has: usability - 0.5871212121212122 and  not_usability - 0.4128787878787879 and original result is: not_usability\n",
      "Test 61 - Has: usability - 0.6753387533875339 and  not_usability - 0.32466124661246615 and original result is: usability\n",
      "Test 62 - Has: usability - 0.663109756097561 and  not_usability - 0.33689024390243905 and original result is: not_usability\n",
      "Test 63 - Has: usability - 0.5611510791366906 and  not_usability - 0.43884892086330934 and original result is: not_usability\n",
      "Test 64 - Has: usability - 0.660996354799514 and  not_usability - 0.33900364520048604 and original result is: usability\n",
      "Test 65 - Has: usability - 0.5714285714285714 and  not_usability - 0.42857142857142855 and original result is: not_usability\n",
      "Test 66 - Has: usability - 0.2 and  not_usability - 0.8 and original result is: not_usability\n",
      "Test 67 - Has: usability - 0.668429003021148 and  not_usability - 0.33157099697885195 and original result is: not_usability\n",
      "Test 68 - Has: usability - 0.5944444444444444 and  not_usability - 0.40555555555555556 and original result is: not_usability\n",
      "Test 69 - Has: usability - 0.6463414634146342 and  not_usability - 0.35365853658536583 and original result is: not_usability\n",
      "Test 70 - Has: usability - 0.6592920353982301 and  not_usability - 0.3407079646017699 and original result is: usability\n",
      "Test 71 - Has: usability - 0.660347551342812 and  not_usability - 0.33965244865718797 and original result is: not_usability\n",
      "Test 72 - Has: usability - 0.6493506493506493 and  not_usability - 0.35064935064935066 and original result is: not_usability\n",
      "Test 73 - Has: usability - 0.3880597014925373 and  not_usability - 0.6119402985074627 and original result is: not_usability\n",
      "Test 74 - Has: usability - 0.6708860759493671 and  not_usability - 0.3291139240506329 and original result is: usability\n",
      "Test 75 - Has: usability - 0.6652719665271967 and  not_usability - 0.33472803347280333 and original result is: usability\n",
      "Test 76 - Has: usability - 0.6998904709748083 and  not_usability - 0.30010952902519167 and original result is: usability\n",
      "Test 77 - Has: usability - 0.6622390891840607 and  not_usability - 0.3377609108159393 and original result is: usability\n",
      "Test 78 - Has: usability - 0.6625141562853907 and  not_usability - 0.33748584371460927 and original result is: not_usability\n"
     ]
    }
   ],
   "source": [
    "for i, classification in enumerate(classifications):\n",
    "    message = \"\"\n",
    "    message = message + f'Test {i} - Has:'\n",
    "    for score in classification['scores']:\n",
    "        message = message + \" \" + score['class_name'] + \" - \" + str(score['score'])  + \" and \"\n",
    "    message = message + \"original result is: \" + classification['test_data']['class_name']\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy is: 0.6329113924050633\n"
     ]
    }
   ],
   "source": [
    "right_answers = 0\n",
    "\n",
    "\n",
    "for i, classification in enumerate(classifications):\n",
    "    higher_score = max(classification['scores'], key=lambda x:x['score'])\n",
    "    if classification['test_data']['class_name'] == higher_score['class_name']:\n",
    "        right_answers += 1\n",
    "\n",
    "print(f'Final accuracy is: {right_answers/len(classifications)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
